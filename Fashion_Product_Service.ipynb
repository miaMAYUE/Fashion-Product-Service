{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8514106",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = '/content/drive/My Drive/hm_fashion_dataset/images.zip'\n",
    "# Unzip images to the local disk of the Colab virtual machine\n",
    "unzip_destination_path = '/content/'\n",
    "\n",
    "# Unzip\n",
    "print(\"Starting to unzip images.zip...\")\n",
    "!unzip -q -n \"{zip_file_path}\" -d \"{unzip_destination_path}\"\n",
    "print(\"Unzipping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "articles_df = pd.read_csv('/content/drive/My Drive/hm_fashion_dataset/articles.csv')\n",
    "\n",
    "# View basic information\n",
    "print(articles_df.info())\n",
    "print(articles_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = articles_df['product_group_name'].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "# Visualize category distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Product Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only categories with more than 1000 samples\n",
    "keep_categories = category_counts[category_counts > 1000].index.tolist()\n",
    "\n",
    "articles_df_filtered = articles_df[articles_df['product_group_name'].isin(keep_categories)].copy()\n",
    "\n",
    "print(f\"\\nOriginal data size: {len(articles_df)}\")\n",
    "print(f\"Data size after filtering: {len(articles_df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f517c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "sample_limit = 8000\n",
    "\n",
    "def limit_samples_per_group(df, group_col, limit):\n",
    "    return df.groupby(group_col).apply(\n",
    "        lambda x: x.sample(n=min(len(x), limit), random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "articles_df_sampled = limit_samples_per_group(articles_df_filtered, 'product_group_name', sample_limit)\n",
    "\n",
    "# View the new category distribution\n",
    "print(\"Category distribution after undersampling:\")\n",
    "print(articles_df_sampled['product_group_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = articles_df_sampled[['article_id', 'product_group_name']].copy()\n",
    "data['label'] = data['product_group_name'].astype('category').cat.codes\n",
    "\n",
    "# Construct image paths\n",
    "GDRIVE_ROOT = '/content/drive/My Drive/'\n",
    "DATASET_FOLDER = 'hm_fashion_dataset'\n",
    "IMAGE_FOLDER_PATH = '/content'\n",
    "def get_image_path(article_id):\n",
    "    str_id = str(article_id).zfill(10)\n",
    "    folder = str_id[:3]\n",
    "    return f'{IMAGE_FOLDER_PATH}/{folder}/{str_id}.jpg'\n",
    "\n",
    "data['image_path'] = data['article_id'].apply(get_image_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% training set and 20% validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=data['label']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Image preprocessing\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['label']\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Image not found at {image_path}, skipping.\")\n",
    "            return None, None\n",
    "\n",
    "# Filter out samples that failed to load (returned None)\n",
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b[0] is not None]\n",
    "    if not batch: return None, None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = FashionDataset(train_df, transform=val_transform) # Temporarily use the same transform as validation\n",
    "val_dataset = FashionDataset(val_df, transform=val_transform)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e91e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ca5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            if inputs is None: continue # Skip empty batches\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation mode\n",
    "        model.eval()\n",
    "        corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if inputs is None: continue\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_acc = torch.tensor(corrects).double() / len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs-1} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        save_path = f'./{model_name}_epoch_{epoch}.pth'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_classes = len(label_map)\n",
    "baseline_model = SimpleCNN(num_classes)\n",
    "\n",
    "# Calculate class weights based on the training set\n",
    "class_counts = train_df['product_group_name'].value_counts()\n",
    "class_weights = 1. / torch.tensor(class_counts.sort_index().values, dtype=torch.float)\n",
    "# Send weights to the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
    "\n",
    "# Start training\n",
    "train_model(baseline_model, \"baseline_cnn\", train_loader, val_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ae368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset_aug = FashionDataset(train_df, transform=train_transform)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning\n",
    "from torchvision import models\n",
    "\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all pre-trained layers\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last layer\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, num_classes) # num_classes is your number of categories\n",
    "\n",
    "# Define a new optimizer that only optimizes the parameters of the new layer\n",
    "optimizer_resnet = optim.Adam(resnet_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Start training with the new DataLoader and new model\n",
    "print(\"\\nTraining ResNet50 with Transfer Learning...\")\n",
    "train_model(resnet_model, \"resnet50\", train_loader_aug, val_loader, criterion, optimizer_resnet, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc300b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def get_all_preds(model, loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "    all_labels = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            if inputs is None: continue\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "            all_labels = torch.cat((all_labels, labels), dim=0)\n",
    "    return all_preds.cpu().numpy(), all_labels.cpu().numpy()\n",
    "\n",
    "y_pred, y_true = get_all_preds(resnet_model, val_loader)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86415368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation before visualization\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Will run model on this device: {device}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Checking 'label_map': Success! Contains {len(label_map)} categories.\")\n",
    "    print(f\"Checking 'val_loader': Success! Contains {len(val_loader)} batches.\")\n",
    "except NameError as e:\n",
    "    print(f\"Error: Required variable not defined - {e}\")\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Create the \"empty shell\" for the ResNet50 model\n",
    "num_classes = len(label_map)\n",
    "best_model = models.resnet50()\n",
    "num_ftrs = best_model.fc.in_features\n",
    "best_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Define the path to the best model\n",
    "best_model_path = '/content/drive/My Drive/hm_fashion_dataset/saved_models/resnet50_epoch_4.pth'\n",
    "\n",
    "# Load weights\n",
    "try:\n",
    "    print(f\"Loading model from {best_model_path}...\")\n",
    "    best_model.to(device) # First, move the model structure to the device\n",
    "    best_model.load_state_dict(torch.load(best_model_path))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at path {best_model_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7290b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Helper function: to convert a PyTorch Tensor image back to a displayable format\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # The image was normalized, we need to un-normalize it\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "def visualize_model_predictions(model, dataloader, label_map, num_images=10):\n",
    "    \"\"\"Visualize model's prediction results\"\"\"\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Get a batch of data from the dataloader\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Get model's prediction results\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # Move data back to CPU for visualization\n",
    "    images = images.cpu()\n",
    "    labels = labels.cpu()\n",
    "    preds = preds.cpu()\n",
    "\n",
    "    # Set canvas size\n",
    "    plt.figure(figsize=(15, 12))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "\n",
    "        # Get the text names for true and predicted labels\n",
    "        true_label = label_map[labels[i].item()]\n",
    "        pred_label = label_map[preds[i].item()]\n",
    "\n",
    "        # Set the title, green if prediction is correct, red if incorrect\n",
    "        title_text = f\"True: {true_label}\\nPred: {pred_label}\"\n",
    "        color = \"green\" if true_label == pred_label else \"red\"\n",
    "\n",
    "        # Display image and title\n",
    "        imshow(images[i], title=title_text)\n",
    "        plt.gca().title.set_color(color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vis_loader = DataLoader(val_dataset, batch_size=10, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "try:\n",
    "    visualize_model_predictions(best_model, vis_loader, label_map, num_images=10)\n",
    "except StopIteration:\n",
    "    print(\"An empty batch was generated, possibly because all images in this batch could not be found. Please re-run this cell to try a new random batch.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
